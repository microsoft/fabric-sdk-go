// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See LICENSE in the project root for license information.
// Code generated by Microsoft (R) AutoRest Code Generator. DO NOT EDIT.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.
// SPDX-License-Identifier: MIT

package sparkjobdefinition

import (
	"context"
	"errors"
	"net/http"
	"net/url"
	"strconv"
	"strings"

	"github.com/Azure/azure-sdk-for-go/sdk/azcore"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/policy"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/runtime"

	"github.com/microsoft/fabric-sdk-go/fabric/core"
)

// BackgroundJobsClient contains the methods for the BackgroundJobs group.
// Don't use this type directly, use a constructor function instead.
type BackgroundJobsClient struct {
	internal *azcore.Client
	endpoint string
}

// RunOnDemandSparkJobDefinition - REQUIRED DELEGATED SCOPES SparkJobDefinition.Execute.All or Item.Execute.All
// MICROSOFT ENTRA SUPPORTED IDENTITIES This API supports the Microsoft identities [/rest/api/fabric/articles/identity-support]
// listed in this section.
// | Identity | Support | |-|-| | User | Yes | | Service principal [/entra/identity-platform/app-objects-and-service-principals#service-principal-object]
// | No | | Managed identities
// [/entra/identity/managed-identities-azure-resources/overview] | No |
// INTERFACE
// If the operation fails it returns an *core.ResponseError type.
//
// Generated from API version v1
//   - workspaceID - The workspace ID.
//   - sparkJobDefinitionID - The Spark job definition item ID.
//   - jobType - The supported job type for Spark job definition is sparkjob.
//   - options - BackgroundJobsClientRunOnDemandSparkJobDefinitionOptions contains the optional parameters for the BackgroundJobsClient.RunOnDemandSparkJobDefinition
//     method.
func (client *BackgroundJobsClient) RunOnDemandSparkJobDefinition(ctx context.Context, workspaceID string, sparkJobDefinitionID string, jobType string, options *BackgroundJobsClientRunOnDemandSparkJobDefinitionOptions) (BackgroundJobsClientRunOnDemandSparkJobDefinitionResponse, error) {
	var err error
	const operationName = "sparkjobdefinition.BackgroundJobsClient.RunOnDemandSparkJobDefinition"
	ctx = context.WithValue(ctx, runtime.CtxAPINameKey{}, operationName)
	ctx, endSpan := runtime.StartSpan(ctx, operationName, client.internal.Tracer(), nil)
	defer func() { endSpan(err) }()
	req, err := client.runOnDemandSparkJobDefinitionCreateRequest(ctx, workspaceID, sparkJobDefinitionID, jobType, options)
	if err != nil {
		return BackgroundJobsClientRunOnDemandSparkJobDefinitionResponse{}, err
	}
	httpResp, err := client.internal.Pipeline().Do(req)
	if err != nil {
		return BackgroundJobsClientRunOnDemandSparkJobDefinitionResponse{}, err
	}
	if !runtime.HasStatusCode(httpResp, http.StatusAccepted) {
		err = core.NewResponseError(httpResp)
		return BackgroundJobsClientRunOnDemandSparkJobDefinitionResponse{}, err
	}
	resp, err := client.runOnDemandSparkJobDefinitionHandleResponse(httpResp)
	return resp, err
}

// runOnDemandSparkJobDefinitionCreateRequest creates the RunOnDemandSparkJobDefinition request.
func (client *BackgroundJobsClient) runOnDemandSparkJobDefinitionCreateRequest(ctx context.Context, workspaceID string, sparkJobDefinitionID string, jobType string, _ *BackgroundJobsClientRunOnDemandSparkJobDefinitionOptions) (*policy.Request, error) {
	urlPath := "/v1/workspaces/{workspaceId}/sparkJobDefinitions/{sparkJobDefinitionId}/jobs/instances"
	if workspaceID == "" {
		return nil, errors.New("parameter workspaceID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{workspaceId}", url.PathEscape(workspaceID))
	if sparkJobDefinitionID == "" {
		return nil, errors.New("parameter sparkJobDefinitionID cannot be empty")
	}
	urlPath = strings.ReplaceAll(urlPath, "{sparkJobDefinitionId}", url.PathEscape(sparkJobDefinitionID))
	req, err := runtime.NewRequest(ctx, http.MethodPost, runtime.JoinPaths(client.endpoint, urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	reqQP.Set("jobType", jobType)
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header["Accept"] = []string{"application/json"}
	return req, nil
}

// runOnDemandSparkJobDefinitionHandleResponse handles the RunOnDemandSparkJobDefinition response.
func (client *BackgroundJobsClient) runOnDemandSparkJobDefinitionHandleResponse(resp *http.Response) (BackgroundJobsClientRunOnDemandSparkJobDefinitionResponse, error) {
	result := BackgroundJobsClientRunOnDemandSparkJobDefinitionResponse{}
	if val := resp.Header.Get("Location"); val != "" {
		result.Location = &val
	}
	if val := resp.Header.Get("Retry-After"); val != "" {
		retryAfter32, err := strconv.ParseInt(val, 10, 32)
		retryAfter := int32(retryAfter32)
		if err != nil {
			return BackgroundJobsClientRunOnDemandSparkJobDefinitionResponse{}, err
		}
		result.RetryAfter = &retryAfter
	}
	return result, nil
}

// Custom code starts below
